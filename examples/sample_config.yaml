# =============================================================================
# Sample Configuration for Phase 2 Generator
# =============================================================================
# Copy this file and modify for your specific container conversion.

# Container to convert (name or tool ID)
container_name: "mod_provider"

# Input tables and their schemas
input_tables:
  # First input stream
  fact_nps:
    databricks_table: "prism_gold.us_insurance.st_fact_nps"
    # Maps to which external input tool in the workflow
    maps_to_tool_id: 3111

  # Second input stream
  fact_response:
    databricks_table: "prism_gold.us_insurance.st_fact_response"
    maps_to_tool_id: 2367
    # Optional: Pre-filter to apply when loading
    pre_filter: >
      (typ_question = 'multiple')
      AND (num_answer != '0')
      AND (NOT lower(id_survey_question) LIKE '%oe%')

# Column mappings: Alteryx column name -> Databricks column name
# Columns NOT listed here will pass through with their original names.
column_mappings:
  # From fact_nps
  nps_type: typ_nps
  verbatim: txt_verbatim
  nps_score: num_nps_score

  # From fact_response
  question_var: id_survey_question
  question_type: typ_question
  answer: txt_answer

# Output configuration
output:
  table_name: "prism_gold.us_insurance.mod_provider"
  columns:
    - provider_name
    - gid_respondent
    - gid_provider
    - gid_time
    - txt_verbatim
    - nps_category
    - nps_category_value
    - nps_weight
    - period
    - val_nps
    - gid_wave
    - num_wave
    - Company_duration
    - date
    - dte_update
    - ind_current_record
    - segment_name
  expected_row_count: 25697  # Optional: for validation

# Notebook settings
notebook:
  output_path: "/Workspace/Users/user@company.com/converted/mod_provider.py"
  add_validation_cell: true
  add_schema_print: true
